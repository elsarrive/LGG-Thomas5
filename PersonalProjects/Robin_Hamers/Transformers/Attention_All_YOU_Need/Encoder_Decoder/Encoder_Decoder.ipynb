{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bdtYHv6u0nCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i30pFFO701R",
        "outputId": "d3fa40ee-2e52-433f-ed19-081d36886b71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xlf46XgTtL8w"
      },
      "outputs": [],
      "source": [
        "# =======================================================\n",
        "# Name: Hamers Robin\n",
        "# GitHub: Rhodham96\n",
        "# Year: 2025\n",
        "# Description: Attention is all you need - Build a GPT from scratch, helped with Andrej Kartpathy video \"Let's build GPT: from scratch, in code, spelled out\"\n",
        "# =======================================================\n",
        "\n",
        "import sentencepiece as spm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "dropout_rate = 0.1\n",
        "vocab_size = 8000\n",
        "max_len = 50 # max seq len\n",
        "n_embd = 384\n"
      ],
      "metadata": {
        "id": "2Bjy9DkB_sqS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "gorXBeeC4pa7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to select the kaggle.json file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "H3gjgLBh4sjM",
        "outputId": "3ad4c469-4dfc-45aa-eb41-694c70fbd2ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78c0ed02-7340-45a4-85bc-11f1b68b4979\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78c0ed02-7340-45a4-85bc-11f1b68b4979\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"robinhamers\",\"key\":\"f4476bf89c5cffe5f8fad8967f0f7b7c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d devicharith/language-translation-englishfrench\n",
        "!unzip /content/language-translation-englishfrench.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ35zeMS4sgE",
        "outputId": "fd837704-6eef-4cdf-b037-61332fefe955"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/devicharith/language-translation-englishfrench\n",
            "License(s): CC0-1.0\n",
            "Archive:  /content/language-translation-englishfrench.zip\n",
            "  inflating: eng_-french.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the CSV file\n",
        "df_import = pd.read_csv('/content/eng_-french.csv')\n",
        "print(df_import.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zmSvT1853lg",
        "outputId": "ecd68805-5fba-42df-f5ca-3df7f3c2abd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  English words/sentences French words/sentences\n",
            "0                     Hi.                 Salut!\n",
            "1                    Run!                Cours !\n",
            "2                    Run!               Courez !\n",
            "3                    Who?                  Qui ?\n",
            "4                    Wow!             Ça alors !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['english'] = df_import['English words/sentences']\n",
        "df['french'] = df_import['French words/sentences']\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59L0AnMO66ca",
        "outputId": "0a493604-84c3-4077-c5d5-d86bbdcf5299"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  english      french\n",
            "0     Hi.      Salut!\n",
            "1    Run!     Cours !\n",
            "2    Run!    Courez !\n",
            "3    Who?       Qui ?\n",
            "4    Wow!  Ça alors !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a combined file with English and French sentences for SentencePiece training\n",
        "with open(\"combined_data.txt\", \"w\") as file:\n",
        "    for e, f in zip(df['english'], df['french']):\n",
        "        file.write(e + '\\n' + f + '\\n')  # Add each English-French sentence pair.\n",
        "\n",
        "# Train the SentencePiece model (bpe-based)\n",
        "spm.SentencePieceTrainer.train(input='combined_data.txt', model_prefix='spm_model', vocab_size=vocab_size, model_type='bpe')\n",
        "\n",
        "sp_en = spm.SentencePieceProcessor(model_file='spm_model.model')\n",
        "sp_fr = spm.SentencePieceProcessor(model_file='spm_model.model')\n",
        "\n",
        "def tokenize(text, sp_processor):\n",
        "    return sp_processor.encode(text, out_type=str)  # Encode to subword tokens\n",
        "\n",
        "# Tokenize English and French sentences\n",
        "df['english_tokens'] = df['english'].apply(lambda x: tokenize(x, sp_en))\n",
        "df['french_tokens'] = df['french'].apply(lambda x: tokenize(x, sp_fr))\n",
        "\n",
        "def tokens_to_indices(tokens, sp_processor):\n",
        "    return sp_processor.encode(' '.join(tokens), out_type=int)  # Convert to indices\n",
        "\n",
        "df['english_indices'] = df['english_tokens'].apply(lambda x: tokens_to_indices(x, sp_en))\n",
        "df['french_indices'] = df['french_tokens'].apply(lambda x: tokens_to_indices(x, sp_fr))\n",
        "\n",
        "max_len = max(df['english_indices'].apply(len).max(), df['french_indices'].apply(len).max())\n"
      ],
      "metadata": {
        "id": "z91dSmQX7znU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2huGprHJCA4z",
        "outputId": "31410ca9-c45a-485c-f3e2-3e7d5652380d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  english      french english_tokens      french_tokens  \\\n",
            "0     Hi.      Salut!     [▁H, i, .]    [▁S, al, ut, !]   \n",
            "1    Run!     Cours !    [▁R, un, !]     [▁C, ours, ▁!]   \n",
            "2    Run!    Courez !    [▁R, un, !]  [▁C, ou, rez, ▁!]   \n",
            "3    Who?       Qui ?      [▁Who, ?]         [▁Qui, ▁?]   \n",
            "4    Wow!  Ça alors !    [▁W, ow, !]  [▁Ça, ▁alors, ▁!]   \n",
            "\n",
            "           english_indices              french_indices  \n",
            "0  [100, 7636, 7926, 7938]  [118, 303, 7926, 190, 244]  \n",
            "1           [570, 68, 244]             [84, 6042, 244]  \n",
            "2           [570, 68, 244]    [84, 695, 70, 7961, 244]  \n",
            "3                [842, 60]                   [964, 60]  \n",
            "4          [79, 6855, 244]            [652, 2327, 244]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour ajouter du padding\n",
        "def pad_sequence(seq, max_len, sp_model):\n",
        "    pad_id = sp_model.piece_to_id('<pad>')  # Obtenir l'ID du token PAD\n",
        "    return seq + [pad_id] * (max_len - len(seq))  # Ajouter le padding jusqu'à max_len\n",
        "\n",
        "# Calculer la longueur maximale des phrases dans les deux langues\n",
        "max_len = max(\n",
        "    df['english_indices'].apply(len).max(),  # Longueur maximale pour l'anglais\n",
        "    df['french_indices'].apply(len).max()   # Longueur maximale pour le français\n",
        ")\n",
        "\n",
        "# Dataset pour la traduction\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, english_sentences, french_sentences, sp_en, sp_fr, max_len):\n",
        "        # Tokenisation des phrases en anglais et français\n",
        "        self.english_sentences = [sp_en.encode(sent, out_type=int) for sent in english_sentences]\n",
        "        self.french_sentences = [sp_fr.encode(sent, out_type=int) for sent in french_sentences]\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Padding des séquences\n",
        "        self.english_sentences = [pad_sequence(sent, max_len, sp_en) for sent in self.english_sentences]\n",
        "        self.french_sentences = [pad_sequence(sent, max_len, sp_fr) for sent in self.french_sentences]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.english_sentences[idx]), torch.tensor(self.french_sentences[idx])\n",
        "\n",
        "# Exemple : Charger les phrases depuis ton DataFrame\n",
        "english_sentences = df['english'].tolist()\n",
        "french_sentences = df['french'].tolist()\n",
        "\n",
        "print(f\"max len = {max_len}\")\n",
        "# Créer le dataset\n",
        "dataset = TranslationDataset(english_sentences, french_sentences, sp_en, sp_fr, max_len)\n",
        "\n",
        "# Créer un DataLoader pour charger les données en lots\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvAbHD4_9Dbl",
        "outputId": "f66bebb4-6212-44e3-97ac-5dd93add9972"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max len = 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" One head of self-attention (for encoder/decoder) \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, embed_dim=n_embd, dropout=dropout_rate):\n",
        "        super().__init__()\n",
        "        print(f\"embed_dim = {embed_dim}\")\n",
        "        print(f\"head size = {head_size}\")\n",
        "        self.key = nn.Linear(embed_dim, head_size, bias=False)\n",
        "        self.query = nn.Linear(embed_dim, head_size, bias=False)\n",
        "        self.value = nn.Linear(embed_dim, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None, encoder_out=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Input tensor.\n",
        "            mask: Optional mask for attention.\n",
        "            encoder_out: Optional encoder output for cross-attention.\n",
        "        \"\"\"\n",
        "        print(f\"x shape = {x.shape}\")\n",
        "        B, T, C = x.shape  # Get dimensions of the input tensor\n",
        "\n",
        "        # If encoder_out is provided, use it for keys and values (cross-attention)\n",
        "        if encoder_out is not None:\n",
        "            # Project encoder_out to embed_dim\n",
        "            print(f\"encoder_out shape = {encoder_out.shape}\")\n",
        "            _, _, encoder_seq_len, encoder_dim = encoder_out.shape  # Get encoder_out dimensions\n",
        "            self.encoder_proj = nn.Linear(encoder_dim, C)  # Initialize encoder_proj\n",
        "            encoder_out = self.encoder_proj(encoder_out)  # Project to embed_dim\n",
        "\n",
        "            # Calculate keys and values from encoder_out\n",
        "            k = self.key(encoder_out)  # (B, T, head_size)\n",
        "            v = self.value(encoder_out)  # (B, T, head_size)\n",
        "        else:  # Otherwise, use x for keys and values (self-attention)\n",
        "            k = self.key(x)  # (B, T, head_size)\n",
        "            v = self.value(x)  # (B, T, head_size)\n",
        "\n",
        "        # Calculate query from input x\n",
        "        q = self.query(x)  # (B, T, head_size)\n",
        "\n",
        "        # Compute attention scores\n",
        "        wei = (q @ k.transpose(-2, -1)) * (C ** -0.5)  # (B, T, T)\n",
        "\n",
        "        # Apply optional padding mask\n",
        "        if mask is not None:\n",
        "            # Reshape mask to match wei's shape for self-attention or cross-attention\n",
        "            # Assuming mask shape is (batch_size, 1, target_sequence_length, source_sequence_length)\n",
        "\n",
        "            # Apply mask to attention scores\n",
        "            # print(f\"wei shape before masking: {wei.shape}\")\n",
        "            # print(f\"mask shape before masking: {mask.shape}\")\n",
        "            wei = wei.masked_fill(mask == 0, float('-inf'))  # Apply mask\n",
        "            # print(wei.shape)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # print(wei.shape)\n",
        "\n",
        "        # Apply dropout\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        # Aggregate values\n",
        "        out = wei @ v  # (B, T, head_size)\n",
        "        return out"
      ],
      "metadata": {
        "id": "mfDqnTbwthCq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" Multi-head attention mechanism \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, head_size, dropout=dropout_rate):\n",
        "        super().__init__()\n",
        "        head_size = embed_dim // num_heads\n",
        "        self.heads = nn.ModuleList([Head(head_size, embed_dim=embed_dim, dropout=dropout) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(num_heads * head_size, embed_dim)  # Projection layer with correct input/output dimensions\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None, encoder_out=None):\n",
        "        # Apply each head to the input and concatenate the results\n",
        "        print(f\"MHA - x shape = {x.shape}\")\n",
        "        out = torch.cat([h(x, mask, encoder_out) for h in self.heads], dim=-1)\n",
        "\n",
        "        # Project the concatenated outputs to the original embedding dimension\n",
        "        out = self.dropout(self.proj(out))\n",
        "        print(f\"MHA - out shape = {out.shape}\")\n",
        "        return out"
      ],
      "metadata": {
        "id": "svscC5PItjMB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non linearity\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, ff_dim, dropout=dropout_rate):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4*ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*ff_dim, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "ZuezIDxftliz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Encoder Layer\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=dropout_rate):\n",
        "        super().__init__()\n",
        "        head_size = embed_dim // num_heads\n",
        "        self.self_attn = MultiHeadAttention(embed_dim, num_heads, head_size, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.feed_forward = FeedForward(embed_dim, ff_dim, dropout=dropout)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        # Self-Attention + Add & Norm\n",
        "        print(f\"x shape = {x.shape}\")\n",
        "        attn_out = self.self_attn(x, mask)\n",
        "        print(f\"attn_out shape = {attn_out.shape}\")\n",
        "        x = self.norm1(x + attn_out)\n",
        "\n",
        "        # Feedforward + Add & Norm\n",
        "        ff_out = self.feed_forward(x)\n",
        "        x = self.norm2(x + ff_out)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "M-3gvxbFzo6T"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Decoder Layer\n",
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=dropout_rate):\n",
        "        super().__init__()\n",
        "        head_size = embed_dim // num_heads # Calculate head_size here\n",
        "        self.self_attn = MultiHeadAttention(embed_dim, num_heads, head_size, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.cross_attn = MultiHeadAttention(embed_dim, num_heads, head_size, dropout=dropout)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.ff = FeedForward(embed_dim, ff_dim, dropout=dropout)\n",
        "        self.norm3 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_out, src_mask=None, tgt_mask=None):\n",
        "\n",
        "        # Self-Attention + Add & Norm\n",
        "        self_attn_out = self.self_attn(x, tgt_mask)\n",
        "        x = self.norm1(x + self_attn_out)\n",
        "        x = self.dropout(x)\n",
        "        # Cross-Attention (Encoder-Decoder)\n",
        "        cross_attn_out = self.cross_attn(x, encoder_out, src_mask)\n",
        "        x = self.norm2(x + cross_attn_out)\n",
        "        x = self.dropout(x)\n",
        "        # Feedforward + Add & Norm\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.norm3(x + ff_out)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "-ip1MeSvzo3B"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Encoder\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, dropout=dropout_rate):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(embed_dim, num_heads, ff_dim, dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-AFhwDJgzo0a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Decoder\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, dropout=dropout_rate):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerDecoderLayer(embed_dim, num_heads, ff_dim, dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "    def forward(self, x, encoder_out, src_mask=None, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_out, src_mask, tgt_mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tcE2faABzoyA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Transformer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads, ff_dim, dropout=dropout_rate):\n",
        "      super().__init__()\n",
        "      self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "      self.encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim, dropout=dropout)\n",
        "      self.decoder = TransformerDecoder(num_layers, embed_dim, num_heads, ff_dim, dropout=dropout)\n",
        "      self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
        "      # Dropout layer\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        src_emb = self.dropout(self.embedding(src))\n",
        "        tgt_emb = self.dropout(self.embedding(tgt))\n",
        "\n",
        "        # Generate masks if not provided\n",
        "        if src_mask is None:\n",
        "            # Generate mask based on src length of tgt for alignment\n",
        "            src_mask = self.generate_mask(src[:, :tgt.shape[1]])\n",
        "        if tgt_mask is None:\n",
        "            tgt_mask = self.generate_decoder_mask(tgt)\n",
        "\n",
        "        # Removing the sequence length adjustment\n",
        "        #src_mask = src_mask[:, :, :tgt.shape[1]] # Adjust src_mask's sequence length\n",
        "\n",
        "        src_mask = src_mask.unsqueeze(1)  # Add a dimension for heads (if necessary)\n",
        "        tgt_mask = tgt_mask.unsqueeze(1)  # Add a dimension for heads (if necessary)\n",
        "\n",
        "        # Align src_emb with target sequence length before passing to encoder\n",
        "        src_emb = src_emb[:, :tgt.shape[1], :]\n",
        "\n",
        "        encoder_out = self.encoder(src_emb, src_mask)\n",
        "        decoder_out = self.decoder(tgt_emb, encoder_out, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(decoder_out)\n",
        "\n",
        "    def generate_mask(self, sequence):\n",
        "      # Get the padding token ID\n",
        "      pad_id = sp_en.piece_to_id('<pad>')\n",
        "      # Create a mask where padding tokens are 0, others are 1\n",
        "      mask = (sequence != pad_id)  # shape: (batch_size, sequence_length)\n",
        "      # Add dimensions for broadcasting (unsqueeze once)\n",
        "      mask = mask.unsqueeze(1)  # shape: (batch_size, 1, sequence_length)\n",
        "\n",
        "      return mask.type(torch.float32)  # or torch.float32, depending on your requirements\n",
        "\n",
        "    def generate_decoder_mask(self, tgt):\n",
        "        # Get the padding token ID\n",
        "        pad_id = sp_en.piece_to_id('<pad>')\n",
        "        # Create a mask where padding tokens are 0, others are 1\n",
        "        mask = (tgt != pad_id)  # shape: (batch_size, sequence_length)\n",
        "        # Add dimensions for broadcasting (unsqueeze once)\n",
        "        mask = mask.unsqueeze(1)  # shape: (batch_size, 1, sequence_length)\n",
        "\n",
        "        # Change the mask type to float32 instead of bool\n",
        "        mask = mask.type(torch.float32)\n",
        "        # Create a subsequent mask (triangular mask)\n",
        "        seq_len = tgt.size(1)  # Get the target sequence length\n",
        "        subsequent_mask = torch.tril(torch.ones(seq_len, seq_len)).type(torch.float32) # shape: (sequence_length, sequence_length)\n",
        "        # Expand dimensions of subsequent_mask to match the padding mask\n",
        "        subsequent_mask = subsequent_mask.unsqueeze(0)\n",
        "        # Combine padding mask and subsequent mask\n",
        "        mask = mask * subsequent_mask\n",
        "\n",
        "        return mask\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UWXCZ1lDzovD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Supposons que tu as déjà défini le modèle Transformer (comme montré précédemment)\n",
        "model = Transformer(vocab_size=len(sp_en), embed_dim=256, num_layers=6, num_heads=8, ff_dim=512, dropout=dropout_rate)\n",
        "\n",
        "# Définir un optimiseur (par exemple Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Définir une fonction de perte (par exemple CrossEntropy pour la traduction)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=sp_en.pad_id())  # Ignorer le PAD token pendant le calcul de la perte\n",
        "\n",
        "# Mettre le modèle en mode entraînement\n",
        "model.train()\n",
        "\n",
        "# Boucle d'entraînement\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0  # Variable pour suivre la perte totale sur un epoch\n",
        "\n",
        "    for i, (src, tgt) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()  # Remettre à zéro les gradients\n",
        "\n",
        "        # Passer les entrées à travers le modèle\n",
        "        print(f\"src shape: {src.shape}\")\n",
        "        print(f\"tgt shape: {tgt[:, :-1].shape}\")\n",
        "        output = model(src, tgt[:, :-1])  # Entrée : src, sortie : tgt décalé d'une position (pour prédire le mot suivant)\n",
        "\n",
        "        # Calculer la perte\n",
        "        # Utilisation de la dernière colonne de la sortie (cible) pour le calcul de la perte\n",
        "        loss = criterion(output.view(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))  # La sortie sans le token de début, et le target sans le token de début\n",
        "\n",
        "        # Calculer les gradients et mettre à jour les poids\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (i + 1) % 100 == 0:  # Afficher la perte tous les 100 batches\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], Loss: {total_loss/100:.4f}\")\n",
        "            total_loss = 0  # Réinitialiser la perte\n",
        "\n",
        "    # Affichage de la perte à la fin de chaque époque\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(dataloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywlHKYEEDOG9",
        "outputId": "a8cb6eb9-cb9a-4b9e-d4c6-76a4cf36e838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "embed_dim = 256\n",
            "head size = 32\n",
            "src shape: torch.Size([32, 98])\n",
            "tgt shape: torch.Size([32, 97])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "MHA - x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "x shape = torch.Size([32, 97, 256])\n",
            "MHA - out shape = torch.Size([32, 32, 97, 256])\n",
            "attn_out shape = torch.Size([32, 32, 97, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ncVi1QIZECK5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}